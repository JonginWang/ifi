{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VEST Database Integration Test\n",
        "\n",
        "This notebook tests the integration of VEST_DB with MySQL database and comprehensive plotting using `plt.ion`.\n",
        "\n",
        "## Test Objectives:\n",
        "1. **VEST_DB Integration**: Load data from MySQL database using VEST_DB\n",
        "2. **main_analysis.py Testing**: Verify main analysis workflow functionality\n",
        "3. **interactive_analysis.py Testing**: Test interactive analysis pipeline\n",
        "4. **Interactive Plotting**: Comprehensive evaluation of `plt.ion` functionality\n",
        "\n",
        "## Features:\n",
        "- VEST data loading from MySQL\n",
        "- Combined visualization of NAS data and VEST data\n",
        "- Interactive plotting with `plt.ion` and `interactive_plotting` context manager\n",
        "- Testing of `main_analysis.py` and `interactive_analysis.py` workflows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Configure Numba threading layer for parallel execution\n",
        "os.environ['NUMBA_THREADING_LAYER'] = 'tbb'\n",
        "\n",
        "# Add project root to path\n",
        "current_dir = Path.cwd()\n",
        "ifi_root = current_dir.parent if current_dir.name == \"analysis\" else current_dir\n",
        "sys.path.insert(0, str(ifi_root))\n",
        "\n",
        "from ifi.utils.cache_setup import setup_project_cache\n",
        "cache_config = setup_project_cache()\n",
        "print(f\"Cache configured: {cache_config['cache_dir']}\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Numba config after setting environment variable\n",
        "try:\n",
        "    import numba\n",
        "    try:\n",
        "        numba.config.THREADING_LAYER = 'tbb'\n",
        "        print(f\"Numba threading layer: {numba.config.THREADING_LAYER}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not set Numba threading layer: {e}\")\n",
        "        print(\"Falling back to default threading layer\")\n",
        "except ImportError:\n",
        "    print(\"Warning: Numba not available\")\n",
        "\n",
        "# Import IFI modules\n",
        "from ifi.db_controller.nas_db import NAS_DB\n",
        "from ifi.db_controller.vest_db import VEST_DB\n",
        "from ifi.analysis import processing, plots\n",
        "from ifi.analysis.main_analysis import run_analysis\n",
        "from ifi.analysis.interactive_analysis import create_mock_args\n",
        "from ifi.utils.file_io import load_results_from_hdf5\n",
        "from ifi.analysis.phi2ne import get_interferometry_params\n",
        "\n",
        "print(\"✓ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "shot_num = 45821  # Change this to your shot number\n",
        "config_path = \"ifi/config.ini\"  # Path to config file\n",
        "results_base_dir = \"results\"  # Base directory for HDF5 results\n",
        "\n",
        "# VEST field IDs to load (common fields: 109=Ip, 101=ne, etc.)\n",
        "# Empty list [] loads all available fields\n",
        "vest_fields = [109, 101]  # Example: Ip and ne fields\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Shot number: {shot_num}\")\n",
        "print(f\"  Config path: {config_path}\")\n",
        "print(f\"  VEST fields: {vest_fields if vest_fields else 'All available'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Database Controllers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"Initializing Database Controllers\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    nas_db = NAS_DB(config_path=config_path)\n",
        "    vest_db = VEST_DB(config_path=config_path)\n",
        "    print(\"✓ Database controllers initialized\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to initialize database controllers: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Data from NAS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(f\"Loading NAS data for shot {shot_num}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Helper function: Extract basename with extension from path (handles UNC paths)\n",
        "def extract_basename(file_path: str) -> str:\n",
        "    \"\"\"Extract basename with extension, handling UNC paths and normalized separators.\"\"\"\n",
        "    normalized = file_path.replace(\"\\\\\", \"/\")\n",
        "    return normalized.split(\"/\")[-1]\n",
        "\n",
        "# Find files for the shot\n",
        "target_files = nas_db.find_files(\n",
        "    query=[shot_num],\n",
        "    data_folders=None,\n",
        "    add_path=False,\n",
        "    force_remote=False,\n",
        ")\n",
        "\n",
        "nas_signals = {}\n",
        "fs = 50e6  # Default sampling frequency\n",
        "force_remote = False  # Set to True to bypass cache\n",
        "\n",
        "if not target_files:\n",
        "    print(f\"⚠ No files found for shot {shot_num} in NAS\")\n",
        "    print(\"Trying to load from existing HDF5 results...\")\n",
        "    h5_results = load_results_from_hdf5(shot_num, base_dir=results_base_dir)\n",
        "    if h5_results and \"signals\" in h5_results:\n",
        "        nas_signals = h5_results[\"signals\"]\n",
        "        metadata = h5_results.get(\"metadata\", {})\n",
        "        fs = metadata.get(\"sampling_frequency\", 50e6)\n",
        "        print(f\"✓ Loaded data from existing HDF5 file\")\n",
        "else:\n",
        "    print(f\"✓ Found {len(target_files)} file(s)\")\n",
        "    for f in target_files:\n",
        "        print(f\"  - {extract_basename(f)}\")\n",
        "    \n",
        "    # Load and process each file\n",
        "    loaded_count = 0\n",
        "    for file_path in target_files:\n",
        "        file_name = extract_basename(file_path)\n",
        "        print(f\"\\nProcessing: {file_name}\")\n",
        "        \n",
        "        df_raw = None\n",
        "        \n",
        "        # Handle UNC paths (won't work via SSH) - use basename for search\n",
        "        if file_path.startswith(\"//\") or file_path.startswith(\"\\\\\\\\\"):\n",
        "            print(f\"  ⚠ UNC path detected - using basename for search\")\n",
        "            try:\n",
        "                data_dict = nas_db.get_shot_data(\n",
        "                    query=[file_name],\n",
        "                    data_folders=None,\n",
        "                    add_path=False,\n",
        "                    force_remote=force_remote\n",
        "                )\n",
        "                # Find matching file by basename\n",
        "                for key in data_dict.keys():\n",
        "                    if extract_basename(key) == file_name:\n",
        "                        df_raw = data_dict[key]\n",
        "                        print(f\"  ✓ Found matching file\")\n",
        "                        break\n",
        "                if df_raw is None and data_dict:\n",
        "                    df_raw = list(data_dict.values())[0]\n",
        "                    print(f\"  ⚠ Using first available file: {extract_basename(list(data_dict.keys())[0])}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠ Error: {type(e).__name__}: {e}\")\n",
        "                continue\n",
        "        else:\n",
        "            # Normal path - direct loading\n",
        "            try:\n",
        "                data_dict = nas_db.get_shot_data(file_path, force_remote=force_remote)\n",
        "                if data_dict and file_path in data_dict:\n",
        "                    df_raw = data_dict[file_path]\n",
        "                    print(f\"  ✓ Loaded from NAS\")\n",
        "                else:\n",
        "                    print(f\"  ⚠ File not found in results, skipping...\")\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠ Error: {type(e).__name__}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Process loaded data\n",
        "        if df_raw is not None:\n",
        "            try:\n",
        "                df_refined = processing.refine_data(df_raw)\n",
        "                df_processed = processing.remove_offset(df_refined, window_size=2001)\n",
        "                nas_signals[file_name] = df_processed\n",
        "                loaded_count += 1\n",
        "                \n",
        "                # Calculate sampling frequency\n",
        "                if \"TIME\" in df_processed.columns:\n",
        "                    time_diff = df_processed[\"TIME\"].diff().mean()\n",
        "                    if pd.notna(time_diff) and time_diff > 0:\n",
        "                        fs = 1 / time_diff\n",
        "                print(f\"  ✓ Processed: shape {df_processed.shape}, fs={fs/1e6:.1f} MHz\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠ Processing error: {type(e).__name__}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    # Fallback to HDF5 if no files loaded\n",
        "    if not nas_signals:\n",
        "        print(f\"\\n⚠ No signals loaded ({loaded_count}/{len(target_files)} files processed)\")\n",
        "        print(f\"  Attempting HDF5 fallback...\")\n",
        "        h5_results = load_results_from_hdf5(shot_num, base_dir=results_base_dir)\n",
        "        if h5_results and \"signals\" in h5_results:\n",
        "            nas_signals = h5_results[\"signals\"]\n",
        "            metadata = h5_results.get(\"metadata\", {})\n",
        "            fs = metadata.get(\"sampling_frequency\", 50e6)\n",
        "            print(f\"✓ Loaded from HDF5 fallback\")\n",
        "\n",
        "# Summary\n",
        "if nas_signals:\n",
        "    print(f\"\\n✓ NAS data loading complete\")\n",
        "    print(f\"  Signals: {list(nas_signals.keys())}\")\n",
        "    for signal_name, signal_df in nas_signals.items():\n",
        "        print(f\"    - {signal_name}: shape {signal_df.shape}, columns: {list(signal_df.columns)}\")\n",
        "    print(f\"  Sampling frequency: {fs/1e6:.1f} MHz\")\n",
        "else:\n",
        "    print(f\"\\n⚠ No NAS signals available\")\n",
        "    print(f\"  Notebook will continue with VEST data only\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load VEST Data from MySQL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(f\"Loading VEST data for shot {shot_num} from MySQL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Connect to VEST database\n",
        "if not vest_db.connect():\n",
        "    print(\"✗ Failed to connect to VEST database\")\n",
        "    vest_data = {}\n",
        "else:\n",
        "    print(\"✓ Connected to VEST database\")\n",
        "    \n",
        "    # Load VEST data\n",
        "    vest_data_dict = vest_db.load_shot(shot=shot_num, fields=vest_fields)\n",
        "    \n",
        "    if vest_data_dict:\n",
        "        print(f\"\\n✓ Loaded VEST data from MySQL\")\n",
        "        print(f\"  Available sampling rates: {list(vest_data_dict.keys())}\")\n",
        "        \n",
        "        for rate, df in vest_data_dict.items():\n",
        "            print(f\"\\n  Sampling rate: {rate}\")\n",
        "            print(f\"    Shape: {df.shape}\")\n",
        "            print(f\"    Columns: {list(df.columns)}\")\n",
        "            print(f\"    Time range: {df.index.min():.6f} to {df.index.max():.6f} s\")\n",
        "            \n",
        "            # Show field labels if available\n",
        "            if hasattr(vest_db, 'field_labels') and vest_db.field_labels:\n",
        "                print(f\"    Field labels:\")\n",
        "                for col in df.columns:\n",
        "                    if col in vest_db.field_labels:\n",
        "                        print(f\"      {col}: {vest_db.field_labels[col]}\")\n",
        "        \n",
        "        vest_data = vest_data_dict\n",
        "    else:\n",
        "        print(f\"⚠ No VEST data found for shot {shot_num}\")\n",
        "        vest_data = {}\n",
        "    \n",
        "    # Disconnect from database\n",
        "    vest_db.disconnect()\n",
        "    print(\"\\n✓ Disconnected from VEST database\")\n",
        "\n",
        "print(f\"\\n✓ VEST data loading complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test main_analysis.py Functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"Testing main_analysis.py Functionality\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create mock args for main_analysis\n",
        "from argparse import Namespace\n",
        "\n",
        "analysis_args = Namespace(\n",
        "    query=[str(shot_num)],\n",
        "    data_folders=None,\n",
        "    add_path=False,\n",
        "    force_remote=False,\n",
        "    results_dir=\"ifi/results\",\n",
        "    no_offset_removal=False,\n",
        "    offset_window=2001,\n",
        "    stft=False,  # Set to True to test STFT\n",
        "    stft_cols=[],\n",
        "    cwt=False,  # Set to True to test CWT\n",
        "    cwt_cols=[],\n",
        "    plot=False,  # Set to True to show plots\n",
        "    no_plot_raw=False,\n",
        "    no_plot_ft=False,\n",
        "    downsample=10,\n",
        "    trigger_time=0.290,\n",
        "    density=False,  # Set to True to test density calculation\n",
        "    vest_fields=vest_fields,\n",
        "    baseline=None,\n",
        "    save_plots=False,\n",
        "    save_data=False,\n",
        "    scheduler=\"threads\",\n",
        ")\n",
        "\n",
        "print(\"\\nAnalysis arguments configured:\")\n",
        "print(f\"  Query: {analysis_args.query}\")\n",
        "print(f\"  STFT: {analysis_args.stft}\")\n",
        "print(f\"  CWT: {analysis_args.cwt}\")\n",
        "print(f\"  Density: {analysis_args.density}\")\n",
        "print(f\"  Plot: {analysis_args.plot}\")\n",
        "print(f\"  VEST fields: {analysis_args.vest_fields}\")\n",
        "\n",
        "# Test run_analysis function\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Running run_analysis function...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    analysis_results = run_analysis(\n",
        "        query=analysis_args.query,\n",
        "        args=analysis_args,\n",
        "        nas_db=nas_db,\n",
        "        vest_db=vest_db,\n",
        "    )\n",
        "    \n",
        "    if analysis_results:\n",
        "        print(\"\\n✓ Analysis completed successfully\")\n",
        "        print(f\"  Processed shots: {list(analysis_results.keys())}\")\n",
        "        \n",
        "        for shot_num_result, bundle in analysis_results.items():\n",
        "            print(f\"\\n  Shot {shot_num_result}:\")\n",
        "            if \"processed_data\" in bundle:\n",
        "                signals = bundle[\"processed_data\"].get(\"signals\")\n",
        "                density = bundle[\"processed_data\"].get(\"density\")\n",
        "                if signals is not None:\n",
        "                    print(f\"    Signals shape: {signals.shape}\")\n",
        "                if density is not None and not density.empty:\n",
        "                    print(f\"    Density shape: {density.shape}\")\n",
        "    else:\n",
        "        print(\"⚠ Analysis returned no results\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error during analysis: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test interactive_analysis.py Functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"Testing interactive_analysis.py Functionality\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create mock args using interactive_analysis function\n",
        "mock_args = create_mock_args()\n",
        "\n",
        "# Modify for current shot\n",
        "mock_args.query = [str(shot_num)]\n",
        "mock_args.vest_fields = vest_fields\n",
        "mock_args.stft = False  # Set to True to test STFT\n",
        "mock_args.cwt = False  # Set to True to test CWT\n",
        "mock_args.density = False  # Set to True to test density\n",
        "mock_args.plot = False  # Set to True to show plots\n",
        "mock_args.scheduler = \"threads\"\n",
        "\n",
        "print(\"\\nMock arguments from interactive_analysis:\")\n",
        "print(f\"  Query: {mock_args.query}\")\n",
        "print(f\"  STFT: {mock_args.stft}\")\n",
        "print(f\"  CWT: {mock_args.cwt}\")\n",
        "print(f\"  Density: {mock_args.density}\")\n",
        "print(f\"  Plot: {mock_args.plot}\")\n",
        "print(f\"  VEST fields: {mock_args.vest_fields}\")\n",
        "\n",
        "# Test run_analysis with mock args\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Running run_analysis with interactive_analysis mock args...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    interactive_results = run_analysis(\n",
        "        query=mock_args.query,\n",
        "        args=mock_args,\n",
        "        nas_db=nas_db,\n",
        "        vest_db=vest_db,\n",
        "    )\n",
        "    \n",
        "    if interactive_results:\n",
        "        print(\"\\n✓ Interactive analysis completed successfully\")\n",
        "        print(f\"  Processed shots: {list(interactive_results.keys())}\")\n",
        "    else:\n",
        "        print(\"⚠ Interactive analysis returned no results\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error during interactive analysis: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_real_torch():\n",
        "    \"\"\"Safely load real torch module, handling dummy torch modules.\"\"\"\n",
        "    import sys\n",
        "    import importlib\n",
        "    \n",
        "    # Check if torch is already loaded and is real (not dummy)\n",
        "    if \"torch\" in sys.modules:\n",
        "        existing_torch = sys.modules[\"torch\"]\n",
        "        # Check if it's a real torch module (has __version__ attribute)\n",
        "        if hasattr(existing_torch, \"__version__\"):\n",
        "            try:\n",
        "                # Try to access version to confirm it's real\n",
        "                _ = existing_torch.__version__\n",
        "                print(f\"✓ Real torch already loaded: version {existing_torch.__version__}\")\n",
        "                return existing_torch\n",
        "            except (AttributeError, RuntimeError):\n",
        "                pass  # Fall through to reload logic\n",
        "    \n",
        "    # Torch is either not loaded or is a dummy - remove it\n",
        "    print(\"Removing dummy/stub torch modules...\")\n",
        "    modules_to_remove = []\n",
        "    for name in list(sys.modules.keys()):\n",
        "        if name == \"torch\" or name.startswith(\"torch.\"):\n",
        "            modules_to_remove.append(name)\n",
        "    \n",
        "    for name in modules_to_remove:\n",
        "        sys.modules.pop(name, None)\n",
        "    \n",
        "    # Invalidate import caches\n",
        "    importlib.invalidate_caches()\n",
        "    \n",
        "    # Try to import real torch\n",
        "    try:\n",
        "        torch = importlib.import_module(\"torch\")\n",
        "        if hasattr(torch, \"__version__\"):\n",
        "            print(f\"✓ Successfully loaded real torch: version {torch.__version__}\")\n",
        "            return torch\n",
        "        else:\n",
        "            raise ImportError(\"Loaded torch module does not have __version__ attribute\")\n",
        "    except (ImportError, RuntimeError, AttributeError) as e:\n",
        "        print(f\"⚠ Error loading torch: {e}\")\n",
        "        print(\"  Note: Torch may already be partially loaded. Try restarting the kernel.\")\n",
        "        raise\n",
        "\n",
        "# Load torch\n",
        "try:\n",
        "    torch = load_real_torch()\n",
        "    print(f\"torch.__version__: {torch.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load torch: {e}\")\n",
        "    print(\"  If torch is already loaded elsewhere, you may need to restart the kernel.\")\n",
        "    torch = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Comprehensive Interactive Plotting Test with plt.ion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"Comprehensive Interactive Plotting Test\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Helper function for downsampling data for plotting\n",
        "def downsample_for_plot(time_data, signal_data, max_points=50000):\n",
        "    \"\"\"\n",
        "    Downsample data if it exceeds max_points for faster plotting.\n",
        "    \n",
        "    Args:\n",
        "        time_data: Time array\n",
        "        signal_data: Signal array\n",
        "        max_points: Maximum number of points to plot (default: 10000)\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (downsampled_time, downsampled_signal, downsample_factor)\n",
        "    \"\"\"\n",
        "    n_points = len(time_data)\n",
        "    if n_points <= max_points:\n",
        "        return time_data, signal_data, 1\n",
        "    \n",
        "    downsample_factor = max(1, n_points // max_points)\n",
        "    downsampled_time = time_data[::downsample_factor]\n",
        "    downsampled_signal = signal_data[::downsample_factor]\n",
        "    \n",
        "    return downsampled_time, downsampled_signal, downsample_factor\n",
        "\n",
        "# Setup interactive mode\n",
        "plots.setup_interactive_mode(backend=\"auto\", style=\"default\")\n",
        "plt.ion()  # Turn on interactive mode\n",
        "print(\"✓ Interactive mode enabled (plt.ion())\")\n",
        "print(f\"  Backend: {matplotlib.get_backend()}\")\n",
        "print(f\"  Interactive: {plt.isinteractive()}\")\n",
        "\n",
        "# Test 1: Using interactive_plotting context manager\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Test 1: Using interactive_plotting context manager\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# --- Figure 1 ---\n",
        "if nas_signals:\n",
        "    with plots.interactive_plotting(show_plots=True, block=False):\n",
        "        signal_name = list(nas_signals.keys())[0]\n",
        "        signal_df = nas_signals[signal_name]\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        if \"TIME\" in signal_df.columns:\n",
        "            time = signal_df[\"TIME\"].values\n",
        "            signal_cols = [col for col in signal_df.columns if col != \"TIME\"]\n",
        "        else:\n",
        "            time = signal_df.index.values\n",
        "            signal_cols = list(signal_df.columns)\n",
        "        \n",
        "        for col in signal_cols[:3]:  # Plot first 3 channels\n",
        "            signal_data = signal_df[col].values\n",
        "            time_ms = time * 1000\n",
        "            \n",
        "            # Downsample if needed\n",
        "            time_plot, signal_plot, ds_factor = downsample_for_plot(time_ms, signal_data)\n",
        "            \n",
        "            if ds_factor > 1:\n",
        "                print(f\"  Note: Downsampling {col} by factor {ds_factor} for plotting\")\n",
        "            \n",
        "            ax.plot(time_plot, signal_plot, label=col, alpha=0.7)\n",
        "        \n",
        "        ax.set_xlabel(\"Time [ms]\")\n",
        "        ax.set_ylabel(\"Amplitude [V]\")\n",
        "        ax.set_title(f\"NAS Signals - Shot {shot_num} - {signal_name}\")\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        print(f\"✓ Created plot: NAS Signals\")\n",
        "else:\n",
        "    print(\"⚠ Skipping NAS signal plot - no NAS data available\")\n",
        "\n",
        "# Test 2: Direct plt.ion() usage\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Test 2: Direct plt.ion() usage\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "plt.ion()  # Ensure interactive mode\n",
        "\n",
        "# Plot VEST data if available\n",
        "# --- Figure 2 ---\n",
        "if vest_data:\n",
        "    for rate, df in vest_data.items():\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        time_base = df.index.values * 1000\n",
        "        \n",
        "        for col in df.columns:\n",
        "            signal_data = df[col].values\n",
        "            \n",
        "            # Downsample if needed\n",
        "            time_plot, signal_plot, ds_factor = downsample_for_plot(time_base, signal_data)\n",
        "            \n",
        "            if ds_factor > 1:\n",
        "                print(f\"  Note: Downsampling {col} by factor {ds_factor} for plotting\")\n",
        "            \n",
        "            ax.plot(time_plot, signal_plot, label=col, alpha=0.7)\n",
        "        \n",
        "        ax.set_xlabel(\"Time [ms]\")\n",
        "        ax.set_ylabel(\"Amplitude\")\n",
        "        ax.set_title(f\"VEST Data - Shot {shot_num} - {rate} sampling rate\")\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        print(f\"✓ Created plot: VEST Data ({rate})\")\n",
        "        \n",
        "        # Only plot first sampling rate for brevity\n",
        "        break\n",
        "\n",
        "# Test 3: Combined NAS and VEST data visualization\n",
        "# --- Figure 3 ---\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Test 3: Combined NAS and VEST Data Visualization\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "if nas_signals and vest_data:\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "    \n",
        "    # Plot NAS signals (top)\n",
        "    signal_name = list(nas_signals.keys())[0]\n",
        "    signal_df = nas_signals[signal_name]\n",
        "    \n",
        "    if \"TIME\" in signal_df.columns:\n",
        "        time_nas = signal_df[\"TIME\"].values\n",
        "        signal_cols = [col for col in signal_df.columns if col != \"TIME\"]\n",
        "    else:\n",
        "        time_nas = signal_df.index.values\n",
        "        signal_cols = list(signal_df.columns)\n",
        "    \n",
        "    for col in signal_cols[:2]:  # Plot first 2 channels\n",
        "        signal_data = signal_df[col].values\n",
        "        time_ms = time_nas * 1000\n",
        "        \n",
        "        # Downsample if needed\n",
        "        time_plot, signal_plot, ds_factor = downsample_for_plot(time_ms, signal_data)\n",
        "        \n",
        "        if ds_factor > 1:\n",
        "            print(f\"  Note: Downsampling NAS {col} by factor {ds_factor} for plotting\")\n",
        "        \n",
        "        axes[0].plot(time_plot, signal_plot, label=f\"NAS: {col}\", alpha=0.7)\n",
        "    \n",
        "    axes[0].set_ylabel(\"Amplitude [V]\")\n",
        "    axes[0].set_title(f\"Combined Analysis - Shot {shot_num}\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot VEST data (bottom)\n",
        "    for rate, df in vest_data.items():\n",
        "        time_base = df.index.values * 1000\n",
        "        for col in df.columns:\n",
        "            signal_data = df[col].values\n",
        "            \n",
        "            # Downsample if needed\n",
        "            time_plot, signal_plot, ds_factor = downsample_for_plot(time_base, signal_data)\n",
        "            \n",
        "            if ds_factor > 1:\n",
        "                print(f\"  Note: Downsampling VEST {col} by factor {ds_factor} for plotting\")\n",
        "            \n",
        "            axes[1].plot(time_plot, signal_plot, label=f\"VEST ({rate}): {col}\", alpha=0.7)\n",
        "        break  # Only first sampling rate\n",
        "    \n",
        "    axes[1].set_xlabel(\"Time [ms]\")\n",
        "    axes[1].set_ylabel(\"Amplitude\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    print(f\"✓ Created combined plot: NAS + VEST Data\")\n",
        "elif vest_data:\n",
        "    print(\"⚠ Skipping combined plot - NAS data not available\")\n",
        "    print(\"   VEST data is available and can be plotted separately (see Test 2)\")\n",
        "elif nas_signals:\n",
        "    print(\"⚠ Skipping combined plot - VEST data not available\")\n",
        "else:\n",
        "    print(\"⚠ Skipping combined plot - neither NAS nor VEST data available\")\n",
        "\n",
        "# Test 4: Using Plotter class with interactive mode\n",
        "# --- Figure 4 ---\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Test 4: Using Plotter class\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "if nas_signals:\n",
        "    plotter = plots.Plotter()\n",
        "    signal_name = list(nas_signals.keys())[0]\n",
        "    signal_df = nas_signals[signal_name]\n",
        "    \n",
        "    # Downsample data if needed before passing to Plotter\n",
        "    signal_df_plot = signal_df.copy()\n",
        "    if \"TIME\" in signal_df.columns:\n",
        "        time_base = signal_df[\"TIME\"].values\n",
        "        n_points = len(time_base)\n",
        "        if n_points > 10000:\n",
        "            ds_factor = max(1, n_points // 10000)\n",
        "            signal_df_plot = signal_df.iloc[::ds_factor].copy()\n",
        "            print(f\"  Note: Downsampling data by factor {ds_factor} for Plotter class\")\n",
        "    elif len(signal_df) > 10000:\n",
        "        ds_factor = max(1, len(signal_df) // 10000)\n",
        "        signal_df_plot = signal_df.iloc[::ds_factor].copy()\n",
        "        print(f\"  Note: Downsampling data by factor {ds_factor} for Plotter class\")\n",
        "    \n",
        "    with plots.interactive_plotting(show_plots=True, block=False):\n",
        "        fig, ax = plotter.plot_waveforms(\n",
        "            signal_df_plot,\n",
        "            title=f\"Plotter Class - Shot {shot_num} - {signal_name}\",\n",
        "            show_plot=True,\n",
        "        )\n",
        "        print(f\"✓ Created plot using Plotter class\")\n",
        "else:\n",
        "    print(\"⚠ Skipping Plotter class test - no NAS data available\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Interactive Plotting Tests Complete\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal figures created: {len(plt.get_fignums())}\")\n",
        "print(\"\\nNote: All plots are in interactive mode.\")\n",
        "print(\"Close plot windows or run plt.close('all') to clear them.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"Test Summary and Evaluation\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. VEST_DB Integration:\")\n",
        "if vest_data:\n",
        "    print(\"   ✓ VEST_DB successfully loaded data from MySQL\")\n",
        "    print(f\"   ✓ Loaded {len(vest_data)} sampling rate group(s)\")\n",
        "    total_fields = sum(len(df.columns) for df in vest_data.values())\n",
        "    print(f\"   ✓ Total fields loaded: {total_fields}\")\n",
        "else:\n",
        "    print(\"   ⚠ No VEST data loaded\")\n",
        "\n",
        "print(\"\\n2. main_analysis.py Functionality:\")\n",
        "if 'analysis_results' in locals() and analysis_results:\n",
        "    print(\"   ✓ run_analysis function executed successfully\")\n",
        "    print(f\"   ✓ Processed {len(analysis_results)} shot(s)\")\n",
        "else:\n",
        "    print(\"   ⚠ run_analysis did not return results\")\n",
        "\n",
        "print(\"\\n3. interactive_analysis.py Functionality:\")\n",
        "if 'interactive_results' in locals() and interactive_results:\n",
        "    print(\"   ✓ create_mock_args function works correctly\")\n",
        "    print(\"   ✓ Interactive analysis pipeline executed successfully\")\n",
        "else:\n",
        "    print(\"   ⚠ Interactive analysis did not return results\")\n",
        "\n",
        "print(\"\\n4. Interactive Plotting (plt.ion):\")\n",
        "print(f\"   ✓ Interactive mode enabled: {plt.isinteractive()}\")\n",
        "print(f\"   ✓ Backend: {matplotlib.get_backend()}\")\n",
        "print(f\"   ✓ Figures created: {len(plt.get_fignums())}\")\n",
        "print(\"   ✓ interactive_plotting context manager works\")\n",
        "print(\"   ✓ Plotter class works with interactive mode\")\n",
        "\n",
        "print(\"\\n5. Data Integration:\")\n",
        "if nas_signals and vest_data:\n",
        "    print(\"   ✓ Successfully combined NAS and VEST data\")\n",
        "    print(\"   ✓ Combined visualization works correctly\")\n",
        "elif nas_signals:\n",
        "    print(\"   ⚠ NAS data available but VEST data not loaded\")\n",
        "    print(\"   ✓ NAS data can be used independently\")\n",
        "elif vest_data:\n",
        "    print(\"   ⚠ VEST data available but NAS data not loaded\")\n",
        "    print(\"   ✓ VEST data can be used independently\")\n",
        "    print(\"   Note: NAS data may be unavailable due to network/VPN/SSH tunnel issues\")\n",
        "else:\n",
        "    print(\"   ⚠ Neither NAS nor VEST data available\")\n",
        "    print(\"   Note: For NAS data, ensure VPN/SSH tunnel is established\")\n",
        "    print(\"   Note: For VEST data, ensure database connection is available\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"All Tests Complete\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Cleanup: Optionally close all figures\n",
        "# Uncomment the line below to close all figures\n",
        "# plt.close('all')\n",
        "# plt.ioff()  # Turn off interactive mode\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
