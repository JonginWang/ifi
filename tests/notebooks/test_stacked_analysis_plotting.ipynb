{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacked Analysis Plotting with Auto-Analysis\n",
        "\n",
        "This notebook provides functionality to:\n",
        "1. Check if results exist for a specified shot number\n",
        "2. Run analysis automatically if required data (density, cwt, stft, etc.) is missing\n",
        "3. Append new analysis results to existing HDF5 files\n",
        "4. Create stacked plots with unified x-axis option\n",
        "\n",
        "## Features\n",
        "- **Auto-Analysis**: Automatically runs missing analysis components\n",
        "- **Append Mode**: Adds new results to existing HDF5 files without overwriting\n",
        "- **Stacked Plotting**: Stack multiple plot types (density, stft, cwt, signals) with shared x-axis\n",
        "- **Flexible Configuration**: Select which plot types to display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "from ifi import IFI_ROOT\n",
        "project_root = IFI_ROOT\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from argparse import Namespace\n",
        "\n",
        "from ifi.analysis.plots import Plotter\n",
        "from ifi.utils.file_io import load_results_from_hdf5\n",
        "from ifi.db_controller.nas_db import NAS_DB\n",
        "from ifi.db_controller.vest_db import VEST_DB\n",
        "from ifi.utils.common import LogManager\n",
        "from ifi.analysis.main_analysis import run_analysis\n",
        "from ifi.analysis.interactive_analysis import create_mock_args\n",
        "\n",
        "# Initialize logging\n",
        "LogManager(level=\"INFO\")\n",
        "logger = LogManager().get_logger(__name__)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python path: {sys.path[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration: Shot Number and Required Data Types\n",
        "\n",
        "Specify the shot number and which data types you need for plotting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "SHOT_NUM = 45821  # Change this to your desired shot number\n",
        "\n",
        "# Specify which data types are required\n",
        "# Options: 'density', 'stft', 'cwt', 'signals', 'vest'\n",
        "# REQUIRED_DATA_TYPES = ['density', 'stft', 'cwt']  # Modify as needed\n",
        "REQUIRED_DATA_TYPES = ['density', 'stft']  # Modify as needed\n",
        "\n",
        "# Analysis options (used when running missing analysis)\n",
        "ANALYSIS_OPTIONS = {\n",
        "    'density': True,\n",
        "    'stft': True,\n",
        "    'cwt': False,\n",
        "    'plot': False,  # Don't show plots during analysis\n",
        "    'save_data': True,  # Save results to HDF5\n",
        "    'save_plots': False,  # Don't save plots during analysis\n",
        "    'scheduler': 'threads',  # Use threads for parallel processing\n",
        "}\n",
        "\n",
        "print(f\"Target shot number: {SHOT_NUM}\")\n",
        "print(f\"Required data types: {REQUIRED_DATA_TYPES}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check Existing Results\n",
        "\n",
        "Check if results exist for the specified shot number and which data types are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_existing_results(shot_num: int, base_dir: str = None) -> dict:\n",
        "    \"\"\"\n",
        "    Check what data types are available in existing results.\n",
        "    \n",
        "    Args:\n",
        "        shot_num: Shot number to check\n",
        "        base_dir: Base directory for results (default: ifi/results)\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary with availability status for each data type\n",
        "    \"\"\"\n",
        "    if base_dir is None:\n",
        "        base_dir = str(project_root / \"ifi\" / \"results\")\n",
        "    \n",
        "    results_dir = Path(base_dir) / str(shot_num)\n",
        "    h5_files = list(results_dir.glob(\"*.h5\")) if results_dir.exists() else []\n",
        "    \n",
        "    availability = {\n",
        "        'file_exists': len(h5_files) > 0,\n",
        "        'h5_files': [str(f) for f in h5_files],\n",
        "        'density': False,\n",
        "        'stft': False,\n",
        "        'cwt': False,\n",
        "        'signals': False,\n",
        "        'vest': False,\n",
        "    }\n",
        "    \n",
        "    if not h5_files:\n",
        "        return availability\n",
        "    \n",
        "    # Check each HDF5 file for available data types\n",
        "    for h5_file in h5_files:\n",
        "        try:\n",
        "            with h5py.File(h5_file, \"r\") as f:\n",
        "                if \"density_data\" in f and len(f[\"density_data\"].keys()) > 0:\n",
        "                    availability['density'] = True\n",
        "                if \"stft_results\" in f and len(f[\"stft_results\"].keys()) > 0:\n",
        "                    availability['stft'] = True\n",
        "                if \"cwt_results\" in f and len(f[\"cwt_results\"].keys()) > 0:\n",
        "                    availability['cwt'] = True\n",
        "                if \"signals\" in f and not f[\"signals\"].attrs.get(\"empty\", False):\n",
        "                    availability['signals'] = True\n",
        "                if \"vest_data\" in f and len(f[\"vest_data\"].keys()) > 0:\n",
        "                    availability['vest'] = True\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error checking {h5_file}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return availability\n",
        "\n",
        "# Check existing results\n",
        "availability = check_existing_results(SHOT_NUM)\n",
        "\n",
        "print(f\"\\nResults check for shot {SHOT_NUM}:\")\n",
        "print(f\"  HDF5 file exists: {availability['file_exists']}\")\n",
        "if availability['file_exists']:\n",
        "    print(f\"  HDF5 files: {availability['h5_files']}\")\n",
        "print(f\"\\nAvailable data types:\")\n",
        "for data_type in ['density', 'stft', 'cwt', 'signals', 'vest']:\n",
        "    status = \"✓\" if availability[data_type] else \"✗\"\n",
        "    required = \" (REQUIRED)\" if data_type in REQUIRED_DATA_TYPES else \"\"\n",
        "    print(f\"  {status} {data_type}{required}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def append_results_to_hdf5(\n",
        "    output_dir: str,\n",
        "    shot_num: int,\n",
        "    signals: dict,\n",
        "    stft_results: dict,\n",
        "    cwt_results: dict,\n",
        "    density_data: pd.DataFrame,\n",
        "    vest_data: pd.DataFrame,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Append analysis results to existing HDF5 file, or create new one if it doesn't exist.\n",
        "    \n",
        "    This function adds new data to existing groups without overwriting existing data.\n",
        "    \"\"\"\n",
        "    import h5py\n",
        "    from ifi.utils.common import ensure_dir_exists\n",
        "    \n",
        "    # Determine filename\n",
        "    if shot_num == 0 and signals is not None and signals:\n",
        "        first_source_file = list(signals.keys())[0]\n",
        "        filename = f\"{Path(first_source_file).stem}.h5\"\n",
        "    else:\n",
        "        filename = f\"{shot_num}.h5\"\n",
        "    \n",
        "    filepath = Path(output_dir) / filename\n",
        "    ensure_dir_exists(str(output_dir))\n",
        "    \n",
        "    # Use 'a' mode to append (or create if doesn't exist)\n",
        "    try:\n",
        "        with h5py.File(filepath, \"a\") as hf:\n",
        "            # Update or create metadata\n",
        "            if \"metadata\" not in hf:\n",
        "                metadata = hf.create_group(\"metadata\")\n",
        "            else:\n",
        "                metadata = hf[\"metadata\"]\n",
        "            metadata.attrs[\"shot_number\"] = shot_num\n",
        "            metadata.attrs[\"updated_at\"] = pd.Timestamp.now().isoformat()\n",
        "            if \"created_at\" not in metadata.attrs:\n",
        "                metadata.attrs[\"created_at\"] = pd.Timestamp.now().isoformat()\n",
        "            metadata.attrs[\"ifi_version\"] = \"1.0\"\n",
        "            \n",
        "            # Append signals data\n",
        "            if signals is not None and signals:\n",
        "                if \"signals\" not in hf:\n",
        "                    signals_group = hf.create_group(\"signals\")\n",
        "                else:\n",
        "                    signals_group = hf[\"signals\"]\n",
        "                    # Remove empty flag if it exists\n",
        "                    if \"empty\" in signals_group.attrs:\n",
        "                        del signals_group.attrs[\"empty\"]\n",
        "                \n",
        "                for signal_name, signal_data in signals.items():\n",
        "                    if isinstance(signal_data, pd.DataFrame):\n",
        "                        # Create or update signal group\n",
        "                        if signal_name not in signals_group:\n",
        "                            signal_group = signals_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_group = signals_group[signal_name]\n",
        "                            # Delete existing datasets to replace them\n",
        "                            for key in list(signal_group.keys()):\n",
        "                                del signal_group[key]\n",
        "                        \n",
        "                        for col in signal_data.columns:\n",
        "                            signal_group.create_dataset(col, data=signal_data[col].values)\n",
        "            \n",
        "            # Append STFT results\n",
        "            if stft_results is not None and stft_results:\n",
        "                if \"stft_results\" not in hf:\n",
        "                    stft_group = hf.create_group(\"stft_results\")\n",
        "                else:\n",
        "                    stft_group = hf[\"stft_results\"]\n",
        "                \n",
        "                for signal_name, stft_data in stft_results.items():\n",
        "                    if isinstance(stft_data, dict):\n",
        "                        if signal_name not in stft_group:\n",
        "                            signal_stft_group = stft_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_stft_group = stft_group[signal_name]\n",
        "                            # Delete existing datasets/attrs to replace them\n",
        "                            for key in list(signal_stft_group.keys()):\n",
        "                                del signal_stft_group[key]\n",
        "                            for key in list(signal_stft_group.attrs.keys()):\n",
        "                                del signal_stft_group.attrs[key]\n",
        "                        \n",
        "                        for key, value in stft_data.items():\n",
        "                            if isinstance(value, np.ndarray):\n",
        "                                signal_stft_group.create_dataset(key, data=value)\n",
        "                            elif isinstance(value, (int, float, str)):\n",
        "                                signal_stft_group.attrs[key] = value\n",
        "            \n",
        "            # Append CWT results\n",
        "            if cwt_results is not None and cwt_results:\n",
        "                if \"cwt_results\" not in hf:\n",
        "                    cwt_group = hf.create_group(\"cwt_results\")\n",
        "                else:\n",
        "                    cwt_group = hf[\"cwt_results\"]\n",
        "                \n",
        "                for signal_name, cwt_data in cwt_results.items():\n",
        "                    if isinstance(cwt_data, dict):\n",
        "                        if signal_name not in cwt_group:\n",
        "                            signal_cwt_group = cwt_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_cwt_group = cwt_group[signal_name]\n",
        "                            # Delete existing datasets/attrs to replace them\n",
        "                            for key in list(signal_cwt_group.keys()):\n",
        "                                del signal_cwt_group[key]\n",
        "                            for key in list(signal_cwt_group.attrs.keys()):\n",
        "                                del signal_cwt_group.attrs[key]\n",
        "                        \n",
        "                        for key, value in cwt_data.items():\n",
        "                            if isinstance(value, np.ndarray):\n",
        "                                signal_cwt_group.create_dataset(key, data=value)\n",
        "                            elif isinstance(value, (int, float, str)):\n",
        "                                signal_cwt_group.attrs[key] = value\n",
        "            \n",
        "            # Append density data\n",
        "            if density_data is not None and not density_data.empty:\n",
        "                if \"density_data\" not in hf:\n",
        "                    density_group = hf.create_group(\"density_data\")\n",
        "                else:\n",
        "                    density_group = hf[\"density_data\"]\n",
        "                    # Delete existing datasets to replace them\n",
        "                    for key in list(density_group.keys()):\n",
        "                        del density_group[key]\n",
        "                \n",
        "                for col in density_data.columns:\n",
        "                    density_group.create_dataset(col, data=density_data[col].values)\n",
        "            \n",
        "            # Append VEST data\n",
        "            if vest_data is not None and not vest_data.empty:\n",
        "                if \"vest_data\" not in hf:\n",
        "                    vest_group = hf.create_group(\"vest_data\")\n",
        "                else:\n",
        "                    vest_group = hf[\"vest_data\"]\n",
        "                    # Delete existing datasets to replace them\n",
        "                    for key in list(vest_group.keys()):\n",
        "                        del vest_group[key]\n",
        "                \n",
        "                for col in vest_data.columns:\n",
        "                    vest_group.create_dataset(col, data=vest_data[col].values)\n",
        "        \n",
        "        print(f\"Results appended to: {filepath}\")\n",
        "        return str(filepath)\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error appending results to HDF5: {e}\")\n",
        "        return None\n",
        "\n",
        "# Determine which data types need to be generated\n",
        "missing_data_types = [dt for dt in REQUIRED_DATA_TYPES if not availability[dt]]\n",
        "\n",
        "if missing_data_types:\n",
        "    print(f\"\\nMissing data types: {missing_data_types}\")\n",
        "    print(\"Running analysis to generate missing data...\")\n",
        "    \n",
        "    try:\n",
        "        nas_db = NAS_DB(config_path=\"ifi/config.ini\")\n",
        "        vest_db = VEST_DB(config_path=\"ifi/config.ini\")\n",
        "        \n",
        "        # Create args for analysis\n",
        "        args = create_mock_args()\n",
        "        args.query = [str(SHOT_NUM)]\n",
        "        args.density = 'density' in missing_data_types or ANALYSIS_OPTIONS.get('density', False)\n",
        "        args.stft = 'stft' in missing_data_types or ANALYSIS_OPTIONS.get('stft', False)\n",
        "        args.cwt = 'cwt' in missing_data_types or ANALYSIS_OPTIONS.get('cwt', False)\n",
        "        args.plot = ANALYSIS_OPTIONS.get('plot', False)\n",
        "        args.save_data = False  # We'll handle saving manually with append\n",
        "        args.save_plots = ANALYSIS_OPTIONS.get('save_plots', False)\n",
        "        args.scheduler = ANALYSIS_OPTIONS.get('scheduler', 'threads')\n",
        "        \n",
        "        # Run analysis\n",
        "        results = run_analysis(\n",
        "            query=args.query,\n",
        "            args=args,\n",
        "            nas_db=nas_db,\n",
        "            vest_db=vest_db,\n",
        "        )\n",
        "        \n",
        "        # Extract results and append to HDF5\n",
        "        if results and str(SHOT_NUM) in results:\n",
        "            shot_results = results[str(SHOT_NUM)]\n",
        "            analysis_bundle = shot_results.get('analysis_results', {})\n",
        "            \n",
        "            # Extract data from analysis bundle\n",
        "            signals_dict = analysis_bundle.get('signals', {})\n",
        "            stft_results = analysis_bundle.get('stft_results', {})\n",
        "            cwt_results = analysis_bundle.get('cwt_results', {})\n",
        "            \n",
        "            # Handle density data (may be dict keyed by frequency)\n",
        "            density_data = analysis_bundle.get('density_data', pd.DataFrame())\n",
        "            if isinstance(density_data, dict):\n",
        "                # Combine all frequency density DataFrames\n",
        "                if density_data:\n",
        "                    first_freq = list(density_data.keys())[0]\n",
        "                    combined_density = density_data[first_freq].copy()\n",
        "                    for freq_key, freq_df in density_data.items():\n",
        "                        if freq_key != first_freq and not freq_df.empty:\n",
        "                            freq_df_reindexed = freq_df.reindex(\n",
        "                                combined_density.index, method=\"nearest\", limit=1\n",
        "                            )\n",
        "                            for col in freq_df_reindexed.columns:\n",
        "                                combined_density[f\"{freq_key}GHz_{col}\"] = freq_df_reindexed[col]\n",
        "                    density_data = combined_density\n",
        "                else:\n",
        "                    density_data = pd.DataFrame()\n",
        "            \n",
        "            vest_data = analysis_bundle.get('vest_data', pd.DataFrame())\n",
        "            \n",
        "            # Append to HDF5\n",
        "            output_dir = str(project_root / \"ifi\" / \"results\" / str(SHOT_NUM))\n",
        "            append_results_to_hdf5(\n",
        "                output_dir,\n",
        "                SHOT_NUM,\n",
        "                signals_dict,\n",
        "                stft_results,\n",
        "                cwt_results,\n",
        "                density_data,\n",
        "                vest_data,\n",
        "            )\n",
        "            \n",
        "            print(\"\\nAnalysis completed and results appended to HDF5 file.\")\n",
        "            \n",
        "            # Refresh availability check\n",
        "            availability = check_existing_results(SHOT_NUM)\n",
        "        else:\n",
        "            print(\"\\nWarning: Analysis did not return expected results.\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to run analysis: {e}\")\n",
        "        raise e\n",
        "else:\n",
        "    print(\"\\nAll required data types are available. Skipping analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results\n",
        "base_dir = str(project_root / \"ifi\" / \"results\")\n",
        "results = load_results_from_hdf5(SHOT_NUM, base_dir=base_dir)\n",
        "\n",
        "if results:\n",
        "    print(f\"\\nLoaded results for shot {SHOT_NUM}:\")\n",
        "    print(f\"  Available keys: {list(results.keys())}\")\n",
        "    \n",
        "    # Extract individual data types\n",
        "    density_data = results.get('density_data', None)\n",
        "    stft_results = results.get('stft_results', {})\n",
        "    cwt_results = results.get('cwt_results', {})\n",
        "    signals = results.get('signals', {})\n",
        "    vest_data = results.get('vest_data', None)\n",
        "    \n",
        "    if density_data is not None:\n",
        "        print(f\"  Density data: shape {density_data.shape}, columns {list(density_data.columns)[:3]}...\")\n",
        "    if stft_results:\n",
        "        print(f\"  STFT results: {list(stft_results.keys())}\")\n",
        "    if cwt_results:\n",
        "        print(f\"  CWT results: {list(cwt_results.keys())}\")\n",
        "    if signals:\n",
        "        print(f\"  Signals: {list(signals.keys())}\")\n",
        "    if vest_data is not None:\n",
        "        print(f\"  VEST data: shape {vest_data.shape}\")\n",
        "else:\n",
        "    print(f\"\\nNo results found for shot {SHOT_NUM}\")\n",
        "    density_data = None\n",
        "    stft_results = {}\n",
        "    cwt_results = {}\n",
        "    signals = {}\n",
        "    vest_data = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Stacked Plots\n",
        "\n",
        "Create stacked plots with optional unified x-axis. Select which plot types to display.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for stacked plotting\n",
        "# VEST field IDs (from VEST database)\n",
        "VEST_FIELDS = {\n",
        "    'Ip': 109,           # Plasma current\n",
        "    'H_alpha': 101,      # H alpha 656 nm\n",
        "    'O_I': 214,          # O I 777 nm\n",
        "    'C_III': 140,        # C III\n",
        "    'Mirnove_Outer': 171, # Outer Mirnove signal\n",
        "}\n",
        "\n",
        "# Create stacked plots (script style, not function)\n",
        "print(\"Creating stacked plots...\")\n",
        "# Check availability of each plot type\n",
        "vest_data = results.get('vest_data', None)\n",
        "density_data = results.get('density_data', None)\n",
        "\n",
        "# 1st row: Plasma current (Ip)\n",
        "has_ip = False\n",
        "ip_cols = []\n",
        "if vest_data is not None:\n",
        "    # Check if Ip column exists (field 109)\n",
        "    ip_cols = [col for col in vest_data.columns if '109' in str(col) or 'Ip' in str(col) or col == 'Ip']\n",
        "    has_ip = len(ip_cols) > 0\n",
        "\n",
        "# 2nd row: 280GHz density\n",
        "has_280ghz = False\n",
        "density_280ghz_cols = []\n",
        "if density_data is not None:\n",
        "    # Find 280GHz density columns\n",
        "    # Pattern: columns starting with \"280GHz_\" or containing \"280GHz\" or \"280\" (but not \"94\")\n",
        "    for col in density_data.columns:\n",
        "        col_str = str(col)\n",
        "        # Check for 280GHz prefix or 280GHz in name\n",
        "        if col_str.startswith('280GHz_') or '280GHz' in col_str:\n",
        "            density_280ghz_cols.append(col)\n",
        "        # Also check for columns with \"280\" but not \"94\" (to avoid false matches)\n",
        "        elif '280' in col_str and '94' not in col_str and '280GHz_' not in col_str:\n",
        "            # Additional check: make sure it's not a 94GHz column with \"280\" in filename\n",
        "            if not any(x in col_str for x in ['94GHz', '94.0']):\n",
        "                density_280ghz_cols.append(col)\n",
        "    has_280ghz = len(density_280ghz_cols) > 0\n",
        "\n",
        "# 3rd row: 94GHz density\n",
        "has_94ghz = False\n",
        "density_94ghz_cols = []\n",
        "if density_data is not None:\n",
        "    # Find 94GHz density columns\n",
        "    # Pattern: columns starting with \"94GHz_\" or containing \"94GHz\" or \"94\" (but not \"280\")\n",
        "    for col in density_data.columns:\n",
        "        col_str = str(col)\n",
        "        # Check for 94GHz prefix or 94GHz in name\n",
        "        if col_str.startswith('94GHz_') or '94GHz' in col_str or '94.0GHz' in col_str:\n",
        "            density_94ghz_cols.append(col)\n",
        "        # Also check for columns with \"94\" but not \"280\" (to avoid false matches)\n",
        "        elif '94' in col_str and '280' not in col_str:\n",
        "            # Make sure it's not already in 280GHz list and doesn't have 280GHz prefix\n",
        "            if col not in density_280ghz_cols and '280GHz' not in col_str:\n",
        "                density_94ghz_cols.append(col)\n",
        "    has_94ghz = len(density_94ghz_cols) > 0\n",
        "    \n",
        "# 4th row: H alpha, O I 777nm, C III\n",
        "has_spectroscopy = False\n",
        "spec_cols = {}\n",
        "if vest_data is not None:\n",
        "    # H alpha (field 101)\n",
        "    h_alpha_cols = [col for col in vest_data.columns if '101' in str(col) or 'H_alpha' in str(col) or 'Halpha' in str(col)]\n",
        "    # O I 777nm (field 214)\n",
        "    o_i_cols = [col for col in vest_data.columns if '214' in str(col) or 'O_I' in str(col) or 'O I' in str(col)]\n",
        "    # C III (field 140)\n",
        "    c_iii_cols = [col for col in vest_data.columns if '140' in str(col) or 'C_III' in str(col) or 'C III' in str(col)]\n",
        "    spec_cols = {'H_alpha': h_alpha_cols, 'O_I': o_i_cols, 'C_III': c_iii_cols}\n",
        "    has_spectroscopy = len(h_alpha_cols) > 0 or len(o_i_cols) > 0 or len(c_iii_cols) > 0\n",
        "\n",
        "# 5th row: Outer Mirnove signal\n",
        "has_mirnove = False\n",
        "mirnove_cols = []\n",
        "if vest_data is not None:\n",
        "    # Outer Mirnove (field 171)\n",
        "    mirnove_cols = [col for col in vest_data.columns if '171' in str(col) or 'Mirnove' in str(col) or 'mirnove' in str(col)]\n",
        "    has_mirnove = len(mirnove_cols) > 0\n",
        "\n",
        "# Build plot list (skip missing 1st and 3rd if needed)\n",
        "plot_list = []\n",
        "if has_ip:\n",
        "    plot_list.append(('ip', None))\n",
        "if has_280ghz:\n",
        "    plot_list.append(('280ghz', density_280ghz_cols))\n",
        "if has_94ghz:\n",
        "    plot_list.append(('94ghz', density_94ghz_cols))\n",
        "if has_spectroscopy:\n",
        "    plot_list.append(('spectroscopy', spec_cols))\n",
        "if has_mirnove:\n",
        "    plot_list.append(('mirnove', mirnove_cols))\n",
        "\n",
        "print(f\"\\nPlot availability:\")\n",
        "print(f\"  Ip: {has_ip}\")\n",
        "print(f\"  280GHz density: {has_280ghz} ({len(density_280ghz_cols)} columns)\")\n",
        "print(f\"  94GHz density: {has_94ghz} ({len(density_94ghz_cols)} columns)\")\n",
        "print(f\"  Spectroscopy: {has_spectroscopy}\")\n",
        "print(f\"  Mirnove: {has_mirnove}\")\n",
        "\n",
        "if not plot_list:\n",
        "    print(\"\\nNo plots to create based on available data.\")\n",
        "else:\n",
        "    n_plots = len(plot_list)\n",
        "    fig, axes = plt.subplots(n_plots, 1, figsize=(14, 3 * n_plots), sharex=True)\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Extract common time axis\n",
        "    common_time = None\n",
        "    if density_data is not None and hasattr(density_data, 'index') and len(density_data.index) > 0:\n",
        "        common_time = density_data.index.values\n",
        "    elif results.get('signals'):\n",
        "        first_signal = list(results['signals'].values())[0]\n",
        "        if 'TIME' in first_signal.columns:\n",
        "            common_time = first_signal['TIME'].values\n",
        "    \n",
        "    plot_idx = 0\n",
        "    \n",
        "    # Plot each row\n",
        "    for plot_type, plot_data in plot_list:\n",
        "        ax = axes[plot_idx]\n",
        "        \n",
        "        if plot_type == 'ip':\n",
        "            # 1st row: Plasma current\n",
        "            if vest_data is not None:\n",
        "                ip_col = ip_cols[0] if ip_cols else None\n",
        "                if ip_col:\n",
        "                    time_ip = vest_data.index.values if hasattr(vest_data, 'index') else None\n",
        "                    if time_ip is None and common_time is not None:\n",
        "                        time_ip = common_time[:len(vest_data)]\n",
        "                    ax.plot(time_ip, vest_data[ip_col].values, label='Ip', color='blue', linewidth=1.5)\n",
        "                    ax.set_ylabel(\"Plasma Current [A]\")\n",
        "                    ax.set_title(f\"Shot {SHOT_NUM}: Plasma Current\")\n",
        "                    ax.legend()\n",
        "                    ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        elif plot_type == '280ghz':\n",
        "            # 2nd row: 280GHz density\n",
        "            if density_data is not None and plot_data:\n",
        "                time_data = density_data.index.values if hasattr(density_data, 'index') else None\n",
        "                if time_data is None and common_time is not None:\n",
        "                    time_data = common_time[:len(density_data)]\n",
        "                for col in plot_data:\n",
        "                    ax.plot(time_data, density_data[col].values, label=col, linewidth=1.5)\n",
        "                ax.set_ylabel(\"Density [m^-3]\")\n",
        "                ax.set_title(f\"Shot {SHOT_NUM}: 280GHz Density\")\n",
        "                ax.legend()\n",
        "                ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        elif plot_type == '94ghz':\n",
        "            # 3rd row: 94GHz density\n",
        "            if density_data is not None and plot_data:\n",
        "                time_data = density_data.index.values if hasattr(density_data, 'index') else None\n",
        "                if time_data is None and common_time is not None:\n",
        "                    time_data = common_time[:len(density_data)]\n",
        "                for col in plot_data:\n",
        "                    ax.plot(time_data, density_data[col].values, label=col, linewidth=1.5)\n",
        "                ax.set_ylabel(\"Density [m^-3]\")\n",
        "                ax.set_title(f\"Shot {SHOT_NUM}: 94GHz Density\")\n",
        "                ax.legend()\n",
        "                ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        elif plot_type == 'spectroscopy':\n",
        "            # 4th row: H alpha, O I 777nm, C III\n",
        "            if vest_data is not None and plot_data:\n",
        "                time_spec = vest_data.index.values if hasattr(vest_data, 'index') else None\n",
        "                if time_spec is None and common_time is not None:\n",
        "                    time_spec = common_time[:len(vest_data)]\n",
        "                \n",
        "                colors = {'H_alpha': 'red', 'O_I': 'green', 'C_III': 'blue'}\n",
        "                for spec_name, spec_col_list in plot_data.items():\n",
        "                    if spec_col_list:\n",
        "                        col = spec_col_list[0]\n",
        "                        ax.plot(time_spec, vest_data[col].values, label=spec_name, color=colors.get(spec_name, 'black'), linewidth=1.5)\n",
        "                ax.set_ylabel(\"Intensity [a.u.]\")\n",
        "                ax.set_title(f\"Shot {SHOT_NUM}: Spectroscopy (H alpha, O I 777nm, C III)\")\n",
        "                ax.legend()\n",
        "                ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        elif plot_type == 'mirnove':\n",
        "            # 5th row: Outer Mirnove signal\n",
        "            if vest_data is not None and plot_data:\n",
        "                time_mirnove = vest_data.index.values if hasattr(vest_data, 'index') else None\n",
        "                if time_mirnove is None and common_time is not None:\n",
        "                    time_mirnove = common_time[:len(vest_data)]\n",
        "                if mirnove_cols:\n",
        "                    col = mirnove_cols[0]\n",
        "                    ax.plot(time_mirnove, vest_data[col].values, label='Outer Mirnove', color='purple', linewidth=1.5)\n",
        "                    ax.set_ylabel(\"Amplitude [a.u.]\")\n",
        "                    ax.set_title(f\"Shot {SHOT_NUM}: Outer Mirnove Signal\")\n",
        "                    ax.legend()\n",
        "                    ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        plot_idx += 1\n",
        "    \n",
        "    # Set x-axis label on bottom plot\n",
        "    if plot_idx > 0:\n",
        "        axes[-1].set_xlabel(\"Time [s]\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"\\nStacked plots created successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create STFT Plots\n",
        "\n",
        "Create STFT spectrograms for 280GHz signals in specified layouts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create STFT plots for 280GHz signals (script style)\n",
        "print(\"\\nCreating STFT plots for 280GHz signals...\")\n",
        "\n",
        "from ifi.analysis.spectrum import SpectrumAnalysis\n",
        "\n",
        "stft_results = results.get('stft_results', {})\n",
        "signals = results.get('signals', {})\n",
        "\n",
        "# If STFT results are missing, compute STFT from signals\n",
        "if not stft_results and signals:\n",
        "    print(\"STFT results not found. Computing STFT from signal data...\")\n",
        "    analyzer = SpectrumAnalysis()\n",
        "    stft_results = {}\n",
        "    \n",
        "    # Get sampling frequency (typically 50 MHz for IFI data)\n",
        "    fs = 50e6  # Default sampling frequency\n",
        "    \n",
        "    # Try to get fs from first signal if available\n",
        "    if signals:\n",
        "        first_signal_key = list(signals.keys())[0]\n",
        "        first_signal_df = signals[first_signal_key]\n",
        "        if 'TIME' in first_signal_df.columns:\n",
        "            time_data = first_signal_df['TIME'].values\n",
        "            if len(time_data) > 1:\n",
        "                dt = np.mean(np.diff(time_data))\n",
        "                if dt > 0:\n",
        "                    fs = 1.0 / dt\n",
        "                    print(f\"  Detected sampling frequency: {fs/1e6:.2f} MHz\")\n",
        "    \n",
        "    # Compute STFT for each signal\n",
        "    for signal_name, signal_df in signals.items():\n",
        "        if 'TIME' not in signal_df.columns:\n",
        "            continue\n",
        "        \n",
        "        # Get channel columns (exclude TIME)\n",
        "        channel_cols = [col for col in signal_df.columns if col != 'TIME']\n",
        "        \n",
        "        for ch_col in channel_cols[:3]:  # Process first 3 channels\n",
        "            signal_data = signal_df[ch_col].values\n",
        "            time_signal = signal_df['TIME'].values\n",
        "            \n",
        "            try:\n",
        "                # Compute STFT\n",
        "                freqs, times, stft_matrix = analyzer.compute_stft(\n",
        "                    signal_data, \n",
        "                    fs=fs,\n",
        "                    t_start=time_signal[0] if len(time_signal) > 0 else 0.0\n",
        "                )\n",
        "                \n",
        "                # Store STFT results\n",
        "                stft_key = f\"{signal_name}_{ch_col}\"\n",
        "                stft_results[stft_key] = {\n",
        "                    'freq': freqs,\n",
        "                    'time': times,\n",
        "                    'stft_matrix': stft_matrix,\n",
        "                    'center_freq': analyzer.find_center_frequency_fft(signal_data, fs)\n",
        "                }\n",
        "                print(f\"  ✓ Computed STFT for {stft_key}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ Failed to compute STFT for {signal_name}/{ch_col}: {e}\")\n",
        "                continue\n",
        "\n",
        "if not stft_results:\n",
        "    print(\"No STFT results available and could not compute from signals.\")\n",
        "else:\n",
        "    shot_str = str(SHOT_NUM)\n",
        "    \n",
        "    # First plot: CH0 and CH1 (1-by-2)\n",
        "    ch0_key = None\n",
        "    ch1_key = None\n",
        "    \n",
        "    # Try to find CH0 and CH1 STFT results\n",
        "    for key in stft_results.keys():\n",
        "        key_lower = key.lower()\n",
        "        # Look for CH0 patterns\n",
        "        if ch0_key is None:\n",
        "            if f\"ch0_{shot_str}_056\" in key_lower or (f\"ch0_{shot_str}\" in key_lower and \"_056\" in key_lower):\n",
        "                ch0_key = key\n",
        "            elif \"ch0\" in key_lower and shot_str in key_lower:\n",
        "                ch0_key = key\n",
        "        # Look for CH1 patterns\n",
        "        if ch1_key is None:\n",
        "            if f\"ch1_{shot_str}_056\" in key_lower or (f\"ch1_{shot_str}\" in key_lower and \"_056\" in key_lower):\n",
        "                ch1_key = key\n",
        "            elif \"ch1\" in key_lower and shot_str in key_lower:\n",
        "                ch1_key = key\n",
        "    \n",
        "    # If not found by pattern, use first two available STFT results\n",
        "    if ch0_key is None or ch1_key is None:\n",
        "        available_keys = list(stft_results.keys())\n",
        "        if len(available_keys) >= 2:\n",
        "            if ch0_key is None:\n",
        "                ch0_key = available_keys[0]\n",
        "            if ch1_key is None and ch0_key != available_keys[1]:\n",
        "                ch1_key = available_keys[1]\n",
        "            elif ch1_key is None and len(available_keys) >= 2:\n",
        "                ch1_key = available_keys[1] if available_keys[1] != ch0_key else available_keys[0]\n",
        "    \n",
        "    if ch0_key and ch1_key:\n",
        "        fig1, axes1 = plt.subplots(1, 2, figsize=(16, 4))\n",
        "        \n",
        "        for idx, (key, ax) in enumerate([(ch0_key, axes1[0]), (ch1_key, axes1[1])]):\n",
        "            stft_data = stft_results[key]\n",
        "            time_stft = stft_data.get('time', stft_data.get('time_STFT', None))\n",
        "            freq_stft = stft_data.get('freq', stft_data.get('freq_STFT', None))\n",
        "            stft_matrix = stft_data.get('stft_matrix', stft_data.get('STFT_matrix', None))\n",
        "            \n",
        "            if stft_matrix is not None and time_stft is not None and freq_stft is not None:\n",
        "                im = ax.pcolormesh(\n",
        "                    time_stft, freq_stft, np.abs(stft_matrix),\n",
        "                    shading='gouraud', cmap='plasma'\n",
        "                )\n",
        "                ax.set_title(f\"Shot {SHOT_NUM}: {key}\")\n",
        "                ax.set_xlabel(\"Time [s]\")\n",
        "                ax.set_ylabel(\"Frequency [Hz]\")\n",
        "                plt.colorbar(im, ax=ax, label=\"Magnitude\")\n",
        "                ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"✓ Created 1-by-2 STFT plot (CH0, CH1)\")\n",
        "    else:\n",
        "        print(f\"⚠ Could not find CH0 or CH1 STFT data for shot {SHOT_NUM}\")\n",
        "    \n",
        "    # Second plot: 3-by-2 layout\n",
        "    # 1st row: CH0_<shotnum>_056, CH1_<shotnum>_056\n",
        "    # 2nd row: CH2_<shotnum>_056, CH0_<shotnum>_789\n",
        "    # 3rd row: CH1_<shotnum>_789, CH2_<shotnum>_789\n",
        "    \n",
        "    channel_patterns = [\n",
        "        (f\"CH0_{shot_str}_056\", \"CH0\"),\n",
        "        (f\"CH1_{shot_str}_056\", \"CH1\"),\n",
        "        (f\"CH2_{shot_str}_056\", \"CH2\"),\n",
        "        (f\"CH0_{shot_str}_789\", \"CH0\"),\n",
        "        (f\"CH1_{shot_str}_789\", \"CH1\"),\n",
        "        (f\"CH2_{shot_str}_789\", \"CH2\"),\n",
        "    ]\n",
        "    \n",
        "    found_keys = []\n",
        "    for pattern, ch_name in channel_patterns:\n",
        "        # Try exact match first\n",
        "        found = None\n",
        "        for key in stft_results.keys():\n",
        "            key_lower = key.lower()\n",
        "            pattern_lower = pattern.lower()\n",
        "            if pattern_lower in key_lower:\n",
        "                found = key\n",
        "                break\n",
        "        if not found:\n",
        "            # Try partial match\n",
        "            for key in stft_results.keys():\n",
        "                key_lower = key.lower()\n",
        "                if ch_name.lower() in key_lower and (f\"_{shot_str}_056\" in key_lower or f\"_{shot_str}_789\" in key_lower):\n",
        "                    # Check if it matches the pattern (056 or 789)\n",
        "                    suffix = pattern.split('_')[2]  # 056 or 789\n",
        "                    if suffix in key_lower:\n",
        "                        found = key\n",
        "                        break\n",
        "        found_keys.append(found)\n",
        "    \n",
        "    if sum(1 for k in found_keys if k is not None) >= 4:  # At least 4 out of 6\n",
        "        fig2, axes2 = plt.subplots(3, 2, figsize=(16, 12))\n",
        "        axes2 = axes2.flatten()\n",
        "        \n",
        "        for idx, (pattern, ch_name) in enumerate(channel_patterns):\n",
        "            key = found_keys[idx]\n",
        "            ax = axes2[idx]\n",
        "            \n",
        "            if key and key in stft_results:\n",
        "                stft_data = stft_results[key]\n",
        "                time_stft = stft_data.get('time', stft_data.get('time_STFT', None))\n",
        "                freq_stft = stft_data.get('freq', stft_data.get('freq_STFT', None))\n",
        "                stft_matrix = stft_data.get('stft_matrix', stft_data.get('STFT_matrix', None))\n",
        "                \n",
        "                if stft_matrix is not None and time_stft is not None and freq_stft is not None:\n",
        "                    im = ax.pcolormesh(\n",
        "                        time_stft, freq_stft, np.abs(stft_matrix),\n",
        "                        shading='gouraud', cmap='plasma'\n",
        "                    )\n",
        "                    ax.set_title(f\"Shot {SHOT_NUM}: {key}\")\n",
        "                    ax.set_xlabel(\"Time [s]\")\n",
        "                    ax.set_ylabel(\"Frequency [Hz]\")\n",
        "                    plt.colorbar(im, ax=ax, label=\"Magnitude\")\n",
        "                    ax.grid(True, alpha=0.3)\n",
        "                else:\n",
        "                    ax.text(0.5, 0.5, f\"No data for {pattern}\", \n",
        "                           ha='center', va='center', transform=ax.transAxes)\n",
        "                    ax.set_title(f\"Shot {SHOT_NUM}: {pattern} (missing)\")\n",
        "            else:\n",
        "                ax.text(0.5, 0.5, f\"Not found: {pattern}\", \n",
        "                       ha='center', va='center', transform=ax.transAxes)\n",
        "                ax.set_title(f\"Shot {SHOT_NUM}: {pattern} (missing)\")\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"✓ Created 3-by-2 STFT plot\")\n",
        "    else:\n",
        "        print(f\"⚠ Could not find enough STFT data for 3-by-2 plot (found {sum(1 for k in found_keys if k is not None)}/6)\")\n",
        "        print(f\"  Available STFT keys: {list(stft_results.keys())[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides:\n",
        "1. ✓ Automatic checking of existing results for specified shot number\n",
        "2. ✓ Automatic analysis execution for missing data types\n",
        "3. ✓ Append mode for adding new results to existing HDF5 files\n",
        "4. ✓ Stacked plotting with specific layout:\n",
        "   - 1st row: Plasma current (Ip)\n",
        "   - 2nd row: 280GHz density\n",
        "   - 3rd row: 94GHz density\n",
        "   - 4th row: H alpha, O I 777nm, C III\n",
        "   - 5th row: Outer Mirnove signal\n",
        "5. ✓ STFT plots for 280GHz signals:\n",
        "   - 1-by-2 layout: CH0, CH1\n",
        "   - 3-by-2 layout: 6 channels (CH0/CH1/CH2 for 056 and 789)\n",
        "\n",
        "### Usage Tips\n",
        "- Modify `SHOT_NUM` to analyze different shots\n",
        "- Adjust `REQUIRED_DATA_TYPES` to specify which analyses are needed\n",
        "- Missing rows (1st or 3rd) are automatically skipped\n",
        "- STFT plots show available channels, missing ones are marked\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
