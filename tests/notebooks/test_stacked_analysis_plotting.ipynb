{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacked Analysis Plotting with Auto-Analysis\n",
        "\n",
        "This notebook provides functionality to:\n",
        "1. Check if results exist for a specified shot number\n",
        "2. Run analysis automatically if required data (density, cwt, stft, etc.) is missing\n",
        "3. Append new analysis results to existing HDF5 files\n",
        "4. Create stacked plots with unified x-axis option\n",
        "\n",
        "## Features\n",
        "- **Auto-Analysis**: Automatically runs missing analysis components\n",
        "- **Append Mode**: Adds new results to existing HDF5 files without overwriting\n",
        "- **Stacked Plotting**: Stack multiple plot types (density, stft, cwt, signals) with shared x-axis\n",
        "- **Flexible Configuration**: Select which plot types to display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "from ifi import IFI_ROOT\n",
        "project_root = IFI_ROOT\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from argparse import Namespace\n",
        "\n",
        "from ifi.analysis.plots import Plotter\n",
        "from ifi.utils.file_io import load_results_from_hdf5\n",
        "from ifi.db_controller.nas_db import NAS_DB\n",
        "from ifi.db_controller.vest_db import VEST_DB\n",
        "from ifi.utils.common import LogManager\n",
        "from ifi.analysis.main_analysis import run_analysis\n",
        "from ifi.analysis.interactive_analysis import create_mock_args\n",
        "\n",
        "# Initialize logging\n",
        "LogManager(level=\"INFO\")\n",
        "logger = LogManager().get_logger(__name__)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python path: {sys.path[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration: Shot Number and Required Data Types\n",
        "\n",
        "Specify the shot number and which data types you need for plotting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "SHOT_NUM = 45821  # Change this to your desired shot number\n",
        "\n",
        "# Specify which data types are required\n",
        "# Options: 'density', 'stft', 'cwt', 'signals', 'vest'\n",
        "REQUIRED_DATA_TYPES = ['density', 'stft', 'cwt']  # Modify as needed\n",
        "\n",
        "# Analysis options (used when running missing analysis)\n",
        "ANALYSIS_OPTIONS = {\n",
        "    'density': True,\n",
        "    'stft': True,\n",
        "    'cwt': True,\n",
        "    'plot': False,  # Don't show plots during analysis\n",
        "    'save_data': True,  # Save results to HDF5\n",
        "    'save_plots': False,  # Don't save plots during analysis\n",
        "    'scheduler': 'threads',  # Use threads for parallel processing\n",
        "}\n",
        "\n",
        "print(f\"Target shot number: {SHOT_NUM}\")\n",
        "print(f\"Required data types: {REQUIRED_DATA_TYPES}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check Existing Results\n",
        "\n",
        "Check if results exist for the specified shot number and which data types are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_existing_results(shot_num: int, base_dir: str = None) -> dict:\n",
        "    \"\"\"\n",
        "    Check what data types are available in existing results.\n",
        "    \n",
        "    Args:\n",
        "        shot_num: Shot number to check\n",
        "        base_dir: Base directory for results (default: ifi/results)\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary with availability status for each data type\n",
        "    \"\"\"\n",
        "    if base_dir is None:\n",
        "        base_dir = str(project_root / \"ifi\" / \"results\")\n",
        "    \n",
        "    results_dir = Path(base_dir) / str(shot_num)\n",
        "    h5_files = list(results_dir.glob(\"*.h5\")) if results_dir.exists() else []\n",
        "    \n",
        "    availability = {\n",
        "        'file_exists': len(h5_files) > 0,\n",
        "        'h5_files': [str(f) for f in h5_files],\n",
        "        'density': False,\n",
        "        'stft': False,\n",
        "        'cwt': False,\n",
        "        'signals': False,\n",
        "        'vest': False,\n",
        "    }\n",
        "    \n",
        "    if not h5_files:\n",
        "        return availability\n",
        "    \n",
        "    # Check each HDF5 file for available data types\n",
        "    for h5_file in h5_files:\n",
        "        try:\n",
        "            with h5py.File(h5_file, \"r\") as f:\n",
        "                if \"density_data\" in f and len(f[\"density_data\"].keys()) > 0:\n",
        "                    availability['density'] = True\n",
        "                if \"stft_results\" in f and len(f[\"stft_results\"].keys()) > 0:\n",
        "                    availability['stft'] = True\n",
        "                if \"cwt_results\" in f and len(f[\"cwt_results\"].keys()) > 0:\n",
        "                    availability['cwt'] = True\n",
        "                if \"signals\" in f and not f[\"signals\"].attrs.get(\"empty\", False):\n",
        "                    availability['signals'] = True\n",
        "                if \"vest_data\" in f and len(f[\"vest_data\"].keys()) > 0:\n",
        "                    availability['vest'] = True\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error checking {h5_file}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return availability\n",
        "\n",
        "# Check existing results\n",
        "availability = check_existing_results(SHOT_NUM)\n",
        "\n",
        "print(f\"\\nResults check for shot {SHOT_NUM}:\")\n",
        "print(f\"  HDF5 file exists: {availability['file_exists']}\")\n",
        "if availability['file_exists']:\n",
        "    print(f\"  HDF5 files: {availability['h5_files']}\")\n",
        "print(f\"\\nAvailable data types:\")\n",
        "for data_type in ['density', 'stft', 'cwt', 'signals', 'vest']:\n",
        "    status = \"✓\" if availability[data_type] else \"✗\"\n",
        "    required = \" (REQUIRED)\" if data_type in REQUIRED_DATA_TYPES else \"\"\n",
        "    print(f\"  {status} {data_type}{required}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def append_results_to_hdf5(\n",
        "    output_dir: str,\n",
        "    shot_num: int,\n",
        "    signals: dict,\n",
        "    stft_results: dict,\n",
        "    cwt_results: dict,\n",
        "    density_data: pd.DataFrame,\n",
        "    vest_data: pd.DataFrame,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Append analysis results to existing HDF5 file, or create new one if it doesn't exist.\n",
        "    \n",
        "    This function adds new data to existing groups without overwriting existing data.\n",
        "    \"\"\"\n",
        "    import h5py\n",
        "    from ifi.utils.common import ensure_dir_exists\n",
        "    \n",
        "    # Determine filename\n",
        "    if shot_num == 0 and signals is not None and signals:\n",
        "        first_source_file = list(signals.keys())[0]\n",
        "        filename = f\"{Path(first_source_file).stem}.h5\"\n",
        "    else:\n",
        "        filename = f\"{shot_num}.h5\"\n",
        "    \n",
        "    filepath = Path(output_dir) / filename\n",
        "    ensure_dir_exists(str(output_dir))\n",
        "    \n",
        "    # Use 'a' mode to append (or create if doesn't exist)\n",
        "    try:\n",
        "        with h5py.File(filepath, \"a\") as hf:\n",
        "            # Update or create metadata\n",
        "            if \"metadata\" not in hf:\n",
        "                metadata = hf.create_group(\"metadata\")\n",
        "            else:\n",
        "                metadata = hf[\"metadata\"]\n",
        "            metadata.attrs[\"shot_number\"] = shot_num\n",
        "            metadata.attrs[\"updated_at\"] = pd.Timestamp.now().isoformat()\n",
        "            if \"created_at\" not in metadata.attrs:\n",
        "                metadata.attrs[\"created_at\"] = pd.Timestamp.now().isoformat()\n",
        "            metadata.attrs[\"ifi_version\"] = \"1.0\"\n",
        "            \n",
        "            # Append signals data\n",
        "            if signals is not None and signals:\n",
        "                if \"signals\" not in hf:\n",
        "                    signals_group = hf.create_group(\"signals\")\n",
        "                else:\n",
        "                    signals_group = hf[\"signals\"]\n",
        "                    # Remove empty flag if it exists\n",
        "                    if \"empty\" in signals_group.attrs:\n",
        "                        del signals_group.attrs[\"empty\"]\n",
        "                \n",
        "                for signal_name, signal_data in signals.items():\n",
        "                    if isinstance(signal_data, pd.DataFrame):\n",
        "                        # Create or update signal group\n",
        "                        if signal_name not in signals_group:\n",
        "                            signal_group = signals_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_group = signals_group[signal_name]\n",
        "                            # Delete existing datasets to replace them\n",
        "                            for key in list(signal_group.keys()):\n",
        "                                del signal_group[key]\n",
        "                        \n",
        "                        for col in signal_data.columns:\n",
        "                            signal_group.create_dataset(col, data=signal_data[col].values)\n",
        "            \n",
        "            # Append STFT results\n",
        "            if stft_results is not None and stft_results:\n",
        "                if \"stft_results\" not in hf:\n",
        "                    stft_group = hf.create_group(\"stft_results\")\n",
        "                else:\n",
        "                    stft_group = hf[\"stft_results\"]\n",
        "                \n",
        "                for signal_name, stft_data in stft_results.items():\n",
        "                    if isinstance(stft_data, dict):\n",
        "                        if signal_name not in stft_group:\n",
        "                            signal_stft_group = stft_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_stft_group = stft_group[signal_name]\n",
        "                            # Delete existing datasets/attrs to replace them\n",
        "                            for key in list(signal_stft_group.keys()):\n",
        "                                del signal_stft_group[key]\n",
        "                            for key in list(signal_stft_group.attrs.keys()):\n",
        "                                del signal_stft_group.attrs[key]\n",
        "                        \n",
        "                        for key, value in stft_data.items():\n",
        "                            if isinstance(value, np.ndarray):\n",
        "                                signal_stft_group.create_dataset(key, data=value)\n",
        "                            elif isinstance(value, (int, float, str)):\n",
        "                                signal_stft_group.attrs[key] = value\n",
        "            \n",
        "            # Append CWT results\n",
        "            if cwt_results is not None and cwt_results:\n",
        "                if \"cwt_results\" not in hf:\n",
        "                    cwt_group = hf.create_group(\"cwt_results\")\n",
        "                else:\n",
        "                    cwt_group = hf[\"cwt_results\"]\n",
        "                \n",
        "                for signal_name, cwt_data in cwt_results.items():\n",
        "                    if isinstance(cwt_data, dict):\n",
        "                        if signal_name not in cwt_group:\n",
        "                            signal_cwt_group = cwt_group.create_group(signal_name)\n",
        "                        else:\n",
        "                            signal_cwt_group = cwt_group[signal_name]\n",
        "                            # Delete existing datasets/attrs to replace them\n",
        "                            for key in list(signal_cwt_group.keys()):\n",
        "                                del signal_cwt_group[key]\n",
        "                            for key in list(signal_cwt_group.attrs.keys()):\n",
        "                                del signal_cwt_group.attrs[key]\n",
        "                        \n",
        "                        for key, value in cwt_data.items():\n",
        "                            if isinstance(value, np.ndarray):\n",
        "                                signal_cwt_group.create_dataset(key, data=value)\n",
        "                            elif isinstance(value, (int, float, str)):\n",
        "                                signal_cwt_group.attrs[key] = value\n",
        "            \n",
        "            # Append density data\n",
        "            if density_data is not None and not density_data.empty:\n",
        "                if \"density_data\" not in hf:\n",
        "                    density_group = hf.create_group(\"density_data\")\n",
        "                else:\n",
        "                    density_group = hf[\"density_data\"]\n",
        "                    # Delete existing datasets to replace them\n",
        "                    for key in list(density_group.keys()):\n",
        "                        del density_group[key]\n",
        "                \n",
        "                for col in density_data.columns:\n",
        "                    density_group.create_dataset(col, data=density_data[col].values)\n",
        "            \n",
        "            # Append VEST data\n",
        "            if vest_data is not None and not vest_data.empty:\n",
        "                if \"vest_data\" not in hf:\n",
        "                    vest_group = hf.create_group(\"vest_data\")\n",
        "                else:\n",
        "                    vest_group = hf[\"vest_data\"]\n",
        "                    # Delete existing datasets to replace them\n",
        "                    for key in list(vest_group.keys()):\n",
        "                        del vest_group[key]\n",
        "                \n",
        "                for col in vest_data.columns:\n",
        "                    vest_group.create_dataset(col, data=vest_data[col].values)\n",
        "        \n",
        "        print(f\"Results appended to: {filepath}\")\n",
        "        return str(filepath)\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error appending results to HDF5: {e}\")\n",
        "        return None\n",
        "\n",
        "# Determine which data types need to be generated\n",
        "missing_data_types = [dt for dt in REQUIRED_DATA_TYPES if not availability[dt]]\n",
        "\n",
        "if missing_data_types:\n",
        "    print(f\"\\nMissing data types: {missing_data_types}\")\n",
        "    print(\"Running analysis to generate missing data...\")\n",
        "    \n",
        "    try:\n",
        "        nas_db = NAS_DB(config_path=\"ifi/config.ini\")\n",
        "        vest_db = VEST_DB(config_path=\"ifi/config.ini\")\n",
        "        \n",
        "        # Create args for analysis\n",
        "        args = create_mock_args()\n",
        "        args.query = [str(SHOT_NUM)]\n",
        "        args.density = 'density' in missing_data_types or ANALYSIS_OPTIONS.get('density', False)\n",
        "        args.stft = 'stft' in missing_data_types or ANALYSIS_OPTIONS.get('stft', False)\n",
        "        args.cwt = 'cwt' in missing_data_types or ANALYSIS_OPTIONS.get('cwt', False)\n",
        "        args.plot = ANALYSIS_OPTIONS.get('plot', False)\n",
        "        args.save_data = False  # We'll handle saving manually with append\n",
        "        args.save_plots = ANALYSIS_OPTIONS.get('save_plots', False)\n",
        "        args.scheduler = ANALYSIS_OPTIONS.get('scheduler', 'threads')\n",
        "        \n",
        "        # Run analysis\n",
        "        results = run_analysis(\n",
        "            query=args.query,\n",
        "            args=args,\n",
        "            nas_db=nas_db,\n",
        "            vest_db=vest_db,\n",
        "        )\n",
        "        \n",
        "        # Extract results and append to HDF5\n",
        "        if results and str(SHOT_NUM) in results:\n",
        "            shot_results = results[str(SHOT_NUM)]\n",
        "            analysis_bundle = shot_results.get('analysis_results', {})\n",
        "            \n",
        "            # Extract data from analysis bundle\n",
        "            signals_dict = analysis_bundle.get('signals', {})\n",
        "            stft_results = analysis_bundle.get('stft_results', {})\n",
        "            cwt_results = analysis_bundle.get('cwt_results', {})\n",
        "            \n",
        "            # Handle density data (may be dict keyed by frequency)\n",
        "            density_data = analysis_bundle.get('density_data', pd.DataFrame())\n",
        "            if isinstance(density_data, dict):\n",
        "                # Combine all frequency density DataFrames\n",
        "                if density_data:\n",
        "                    first_freq = list(density_data.keys())[0]\n",
        "                    combined_density = density_data[first_freq].copy()\n",
        "                    for freq_key, freq_df in density_data.items():\n",
        "                        if freq_key != first_freq and not freq_df.empty:\n",
        "                            freq_df_reindexed = freq_df.reindex(\n",
        "                                combined_density.index, method=\"nearest\", limit=1\n",
        "                            )\n",
        "                            for col in freq_df_reindexed.columns:\n",
        "                                combined_density[f\"{freq_key}GHz_{col}\"] = freq_df_reindexed[col]\n",
        "                    density_data = combined_density\n",
        "                else:\n",
        "                    density_data = pd.DataFrame()\n",
        "            \n",
        "            vest_data = analysis_bundle.get('vest_data', pd.DataFrame())\n",
        "            \n",
        "            # Append to HDF5\n",
        "            output_dir = str(project_root / \"ifi\" / \"results\" / str(SHOT_NUM))\n",
        "            append_results_to_hdf5(\n",
        "                output_dir,\n",
        "                SHOT_NUM,\n",
        "                signals_dict,\n",
        "                stft_results,\n",
        "                cwt_results,\n",
        "                density_data,\n",
        "                vest_data,\n",
        "            )\n",
        "            \n",
        "            print(\"\\nAnalysis completed and results appended to HDF5 file.\")\n",
        "            \n",
        "            # Refresh availability check\n",
        "            availability = check_existing_results(SHOT_NUM)\n",
        "        else:\n",
        "            print(\"\\nWarning: Analysis did not return expected results.\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to run analysis: {e}\")\n",
        "        raise e\n",
        "else:\n",
        "    print(\"\\nAll required data types are available. Skipping analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results\n",
        "base_dir = str(project_root / \"ifi\" / \"results\")\n",
        "results = load_results_from_hdf5(SHOT_NUM, base_dir=base_dir)\n",
        "\n",
        "if results:\n",
        "    print(f\"\\nLoaded results for shot {SHOT_NUM}:\")\n",
        "    print(f\"  Available keys: {list(results.keys())}\")\n",
        "    \n",
        "    # Extract individual data types\n",
        "    density_data = results.get('density_data', None)\n",
        "    stft_results = results.get('stft_results', {})\n",
        "    cwt_results = results.get('cwt_results', {})\n",
        "    signals = results.get('signals', {})\n",
        "    vest_data = results.get('vest_data', None)\n",
        "    \n",
        "    if density_data is not None:\n",
        "        print(f\"  Density data: shape {density_data.shape}, columns {list(density_data.columns)[:3]}...\")\n",
        "    if stft_results:\n",
        "        print(f\"  STFT results: {list(stft_results.keys())}\")\n",
        "    if cwt_results:\n",
        "        print(f\"  CWT results: {list(cwt_results.keys())}\")\n",
        "    if signals:\n",
        "        print(f\"  Signals: {list(signals.keys())}\")\n",
        "    if vest_data is not None:\n",
        "        print(f\"  VEST data: shape {vest_data.shape}\")\n",
        "else:\n",
        "    print(f\"\\nNo results found for shot {SHOT_NUM}\")\n",
        "    density_data = None\n",
        "    stft_results = {}\n",
        "    cwt_results = {}\n",
        "    signals = {}\n",
        "    vest_data = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Stacked Plots\n",
        "\n",
        "Create stacked plots with optional unified x-axis. Select which plot types to display.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for stacked plotting\n",
        "PLOT_CONFIG = {\n",
        "    'plot_density': True,  # Plot density data\n",
        "    'plot_stft': True,     # Plot STFT spectrograms\n",
        "    'plot_cwt': False,     # Plot CWT spectrograms\n",
        "    'plot_signals': False, # Plot raw signals\n",
        "    'plot_vest': False,    # Plot VEST data\n",
        "    'unified_xaxis': True, # Use unified x-axis for all subplots\n",
        "    'figsize': (14, 10),   # Figure size\n",
        "}\n",
        "\n",
        "def create_stacked_plots(\n",
        "    results: dict,\n",
        "    plot_config: dict,\n",
        "    shot_num: int,\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Create stacked plots with optional unified x-axis.\n",
        "    \n",
        "    Args:\n",
        "        results: Dictionary containing loaded results\n",
        "        plot_config: Configuration dictionary for plotting\n",
        "        shot_num: Shot number for title\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (figure, axes) matplotlib objects\n",
        "    \"\"\"\n",
        "    plotter = Plotter()\n",
        "    \n",
        "    # Determine which plots to create\n",
        "    plot_list = []\n",
        "    if plot_config.get('plot_density', False) and results.get('density_data') is not None:\n",
        "        plot_list.append('density')\n",
        "    if plot_config.get('plot_stft', False) and results.get('stft_results'):\n",
        "        plot_list.append('stft')\n",
        "    if plot_config.get('plot_cwt', False) and results.get('cwt_results'):\n",
        "        plot_list.append('cwt')\n",
        "    if plot_config.get('plot_signals', False) and results.get('signals'):\n",
        "        plot_list.append('signals')\n",
        "    if plot_config.get('plot_vest', False) and results.get('vest_data') is not None:\n",
        "        plot_list.append('vest')\n",
        "    \n",
        "    if not plot_list:\n",
        "        print(\"No plots to create based on configuration and available data.\")\n",
        "        return None, None\n",
        "    \n",
        "    n_plots = len(plot_list)\n",
        "    figsize = plot_config.get('figsize', (14, 4 * n_plots))\n",
        "    sharex = 'all' if plot_config.get('unified_xaxis', True) else None\n",
        "    \n",
        "    fig, axes = plt.subplots(n_plots, 1, figsize=figsize, sharex=sharex)\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Extract common time axis if unified x-axis is requested\n",
        "    common_time = None\n",
        "    if plot_config.get('unified_xaxis', True):\n",
        "        # Try to get time from density data first\n",
        "        if results.get('density_data') is not None:\n",
        "            density_df = results['density_data']\n",
        "            if hasattr(density_df, 'index') and len(density_df.index) > 0:\n",
        "                common_time = density_df.index.values\n",
        "        # Fallback to signals\n",
        "        if common_time is None and results.get('signals'):\n",
        "            first_signal = list(results['signals'].values())[0]\n",
        "            if 'TIME' in first_signal.columns:\n",
        "                common_time = first_signal['TIME'].values\n",
        "    \n",
        "    plot_idx = 0\n",
        "    \n",
        "    # Plot density\n",
        "    if 'density' in plot_list:\n",
        "        density_data = results['density_data']\n",
        "        time_data = density_data.index.values if hasattr(density_data, 'index') else None\n",
        "        if time_data is None and common_time is not None:\n",
        "            time_data = common_time[:len(density_data)]\n",
        "        \n",
        "        # Use plot_density with ax parameter if available\n",
        "        try:\n",
        "            fig_d, ax_d = plotter.plot_density(\n",
        "                density_data,\n",
        "                time_data=time_data,\n",
        "                title=f\"Shot {shot_num}: Density\",\n",
        "                show_plot=False,\n",
        "            )\n",
        "            # Copy plot to our subplot\n",
        "            if ax_d is not None:\n",
        "                ax_d.remove()\n",
        "                axes[plot_idx].clear()\n",
        "                # Replot on our axis\n",
        "                for col in density_data.columns:\n",
        "                    axes[plot_idx].plot(time_data, density_data[col].values, label=col)\n",
        "                axes[plot_idx].set_title(f\"Shot {shot_num}: Density\")\n",
        "                axes[plot_idx].set_ylabel(\"Density [m^-3]\")\n",
        "                axes[plot_idx].legend()\n",
        "                axes[plot_idx].grid(True, alpha=0.3)\n",
        "                plt.close(fig_d)\n",
        "        except Exception as e:\n",
        "            # Fallback: simple plotting\n",
        "            for col in density_data.columns:\n",
        "                axes[plot_idx].plot(time_data, density_data[col].values, label=col)\n",
        "            axes[plot_idx].set_title(f\"Shot {shot_num}: Density\")\n",
        "            axes[plot_idx].set_ylabel(\"Density [m^-3]\")\n",
        "            axes[plot_idx].legend()\n",
        "            axes[plot_idx].grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # Plot STFT\n",
        "    if 'stft' in plot_list:\n",
        "        stft_results = results['stft_results']\n",
        "        # Plot first available STFT result\n",
        "        if stft_results:\n",
        "            first_stft_key = list(stft_results.keys())[0]\n",
        "            stft_data = stft_results[first_stft_key]\n",
        "            \n",
        "            time_stft = stft_data.get('time', stft_data.get('time_STFT', None))\n",
        "            freq_stft = stft_data.get('freq', stft_data.get('freq_STFT', None))\n",
        "            stft_matrix = stft_data.get('stft_matrix', stft_data.get('STFT_matrix', None))\n",
        "            \n",
        "            if time_stft is None and common_time is not None:\n",
        "                time_stft = common_time[:stft_matrix.shape[1]] if stft_matrix is not None else None\n",
        "            \n",
        "            if stft_matrix is not None and time_stft is not None and freq_stft is not None:\n",
        "                im = axes[plot_idx].pcolormesh(\n",
        "                    time_stft, freq_stft, np.abs(stft_matrix),\n",
        "                    shading='gouraud', cmap='plasma'\n",
        "                )\n",
        "                axes[plot_idx].set_title(f\"Shot {shot_num}: STFT ({first_stft_key})\")\n",
        "                axes[plot_idx].set_ylabel(\"Frequency [Hz]\")\n",
        "                plt.colorbar(im, ax=axes[plot_idx], label=\"Magnitude\")\n",
        "                axes[plot_idx].grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # Plot CWT\n",
        "    if 'cwt' in plot_list:\n",
        "        cwt_results = results['cwt_results']\n",
        "        # Plot first available CWT result\n",
        "        if cwt_results:\n",
        "            first_cwt_key = list(cwt_results.keys())[0]\n",
        "            cwt_data = cwt_results[first_cwt_key]\n",
        "            \n",
        "            time_cwt = cwt_data.get('time', cwt_data.get('time_CWT', None))\n",
        "            scales_cwt = cwt_data.get('scales', cwt_data.get('freq_CWT', None))\n",
        "            cwt_matrix = cwt_data.get('cwt_matrix', cwt_data.get('CWT_matrix', None))\n",
        "            \n",
        "            if time_cwt is None and common_time is not None:\n",
        "                time_cwt = common_time[:cwt_matrix.shape[1]] if cwt_matrix is not None else None\n",
        "            \n",
        "            if cwt_matrix is not None and time_cwt is not None and scales_cwt is not None:\n",
        "                im = axes[plot_idx].pcolormesh(\n",
        "                    time_cwt, scales_cwt, np.abs(cwt_matrix),\n",
        "                    shading='gouraud', cmap='plasma'\n",
        "                )\n",
        "                axes[plot_idx].set_title(f\"Shot {shot_num}: CWT ({first_cwt_key})\")\n",
        "                axes[plot_idx].set_ylabel(\"Scale\")\n",
        "                plt.colorbar(im, ax=axes[plot_idx], label=\"Magnitude\")\n",
        "                axes[plot_idx].grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # Plot signals\n",
        "    if 'signals' in plot_list:\n",
        "        signals = results['signals']\n",
        "        if signals:\n",
        "            first_signal_key = list(signals.keys())[0]\n",
        "            signal_df = signals[first_signal_key]\n",
        "            \n",
        "            if 'TIME' in signal_df.columns:\n",
        "                time_sig = signal_df['TIME'].values\n",
        "                for col in signal_df.columns:\n",
        "                    if col != 'TIME':\n",
        "                        axes[plot_idx].plot(time_sig, signal_df[col].values, label=col)\n",
        "                axes[plot_idx].set_title(f\"Shot {shot_num}: Signals ({first_signal_key})\")\n",
        "                axes[plot_idx].set_ylabel(\"Amplitude [V]\")\n",
        "                axes[plot_idx].legend()\n",
        "                axes[plot_idx].grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # Plot VEST data\n",
        "    if 'vest' in plot_list:\n",
        "        vest_data = results['vest_data']\n",
        "        if vest_data is not None:\n",
        "            time_vest = vest_data.index.values if hasattr(vest_data, 'index') else None\n",
        "            if time_vest is None and common_time is not None:\n",
        "                time_vest = common_time[:len(vest_data)]\n",
        "            \n",
        "            # Plot first VEST column\n",
        "            if len(vest_data.columns) > 0:\n",
        "                first_col = vest_data.columns[0]\n",
        "                axes[plot_idx].plot(time_vest, vest_data[first_col].values, label=first_col)\n",
        "                axes[plot_idx].set_title(f\"Shot {shot_num}: VEST Data\")\n",
        "                axes[plot_idx].set_ylabel(first_col)\n",
        "                axes[plot_idx].legend()\n",
        "                axes[plot_idx].grid(True, alpha=0.3)\n",
        "                plot_idx += 1\n",
        "    \n",
        "    # Set x-axis label on bottom plot only if unified\n",
        "    if plot_config.get('unified_xaxis', True) and plot_idx > 0:\n",
        "        axes[-1].set_xlabel(\"Time [s]\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    return fig, axes\n",
        "\n",
        "# Create stacked plots\n",
        "if results:\n",
        "    fig, axes = create_stacked_plots(results, PLOT_CONFIG, SHOT_NUM)\n",
        "    if fig is not None:\n",
        "        plt.show()\n",
        "        print(\"\\nStacked plots created successfully.\")\n",
        "    else:\n",
        "        print(\"\\nCould not create plots. Check data availability and plot configuration.\")\n",
        "else:\n",
        "    print(\"\\nNo results available for plotting.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides:\n",
        "1. ✓ Automatic checking of existing results for specified shot number\n",
        "2. ✓ Automatic analysis execution for missing data types\n",
        "3. ✓ Append mode for adding new results to existing HDF5 files\n",
        "4. ✓ Stacked plotting with unified x-axis option\n",
        "\n",
        "### Usage Tips\n",
        "- Modify `SHOT_NUM` to analyze different shots\n",
        "- Adjust `REQUIRED_DATA_TYPES` to specify which analyses are needed\n",
        "- Configure `PLOT_CONFIG` to select which plots to display\n",
        "- Set `unified_xaxis=True` to align all plots on the same time axis\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
